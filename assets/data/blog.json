[
  {
    "id": "cti-sentinel",
    "title": "CTI Sentinel: Building a Fully Local Cyber Threat Intelligence Platform",
    "category": "blueprint",
    "summary": "How I built a 100% local CTI platform that collects from 30+ OSINT sources, processes articles through a local LLM, correlates entities across a MITRE ATT&CK heatmap, and serves everything via a FastAPI + Streamlit stack — with zero cloud dependency.",
    "content": "<h2>CTI Sentinel: Building a Fully Local Cyber Threat Intelligence Platform</h2><p>Most CTI platforms are cloud-hosted SaaS products. They ingest your feeds, process your IOCs, and store your threat data on someone else's infrastructure. That's fine for enterprise teams with budget and compliance frameworks — but for a student, a solo analyst, or anyone who wants to <strong>actually understand how CTI works under the hood</strong>, it's a black box.</p><p>So I built my own. <strong>CTI Sentinel</strong> is a fully local, open-source CTI platform designed for learning, experimentation, and personal threat intelligence. Everything runs on your machine — including the LLM.</p><h2>1 — Why Build This?</h2><p>Three reasons drove this project:</p><ul><li><strong>Learning by doing</strong> — Reading about MITRE ATT&CK is one thing. Building a system that automatically maps collected articles to TTPs, scores severity, extracts IOCs, and correlates threat actors is something entirely different.</li><li><strong>Privacy</strong> — No data leaves the machine. The only outbound traffic is to public OSINT APIs (NVD, OTX, abuse.ch, RSS feeds). Everything else — processing, storage, analysis — stays local.</li><li><strong>Full control</strong> — I wanted to understand every layer: collection, processing, storage, correlation, alerting, visualization. No abstraction, no SDK magic, no vendor lock-in.</li></ul><h2>2 — Architecture Overview</h2><p>CTI Sentinel is structured as a modular Python application with six core components:</p><h3>Collectors (30+ Sources)</h3><p>The collection engine orchestrates parallel fetching from multiple source types:</p><ul><li><strong>RSS/Atom feeds</strong> — CERT-FR, BleepingComputer, The Hacker News, KrebsOnSecurity, Dark Reading, Mandiant, CrowdStrike, SentinelOne, Talos Intelligence, Exploit-DB, and more. Polled every 30 minutes.</li><li><strong>REST APIs</strong> — NVD (NIST) for CVEs, AlienVault OTX for IOC pulses, URLhaus/MalwareBazaar/ThreatFox from abuse.ch for malicious URLs and samples, MITRE ATT&CK for TTPs and threat actor profiles. Polled every 2–6 hours depending on rate limits.</li></ul><p>Each collector inherits from a base class that handles caching, rate limiting, error recovery, and deduplication. The engine runs them in parallel with <code>asyncio</code> and <code>aiohttp</code>, respecting per-source rate limits.</p><h3>LLM Processor (Ollama)</h3><p>This is where it gets interesting. Raw articles are just text — the LLM turns them into structured intelligence. The processing pipeline has six stages:</p><ol><li><strong>Severity scoring</strong> — The LLM classifies each article on a five-level scale: CRITICAL, HIGH, MEDIUM, LOW, INFO. The prompt is calibrated for CTI context: a 0-day with active exploitation is CRITICAL, a research paper is INFO.</li><li><strong>French summarization</strong> — Every article gets a concise summary in French (the dashboard interface language).</li><li><strong>IOC extraction</strong> — A regex engine extracts 14 types of IOCs: IPv4, IPv6, domains, URLs, MD5, SHA1, SHA256, email addresses, CVE IDs, YARA rules, JA3 fingerprints, and more. The LLM then validates and contextualizes each IOC.</li><li><strong>TTP identification</strong> — The LLM maps article content to MITRE ATT&CK techniques, with confidence levels and evidence citations.</li><li><strong>Threat actor and malware linking</strong> — Named entities (APT groups, malware families, campaigns) are extracted and linked to the knowledge base.</li><li><strong>Flashcard generation</strong> — For the learning module, the LLM generates quiz-style flashcards from each article, with varying difficulty levels.</li></ol><p>The LLM runs entirely locally via <strong>Ollama</strong> — Mistral 7B or Llama3 8B. No API key, no cloud, no token cost. Just your GPU (or CPU if you're patient).</p><h3>Database (SQLAlchemy + SQLite)</h3><p>The data model has <strong>14 SQLAlchemy models</strong> with <strong>13 many-to-many relationships</strong>:</p><ul><li>Articles, Vulnerabilities (CVE), IOCs, Threat Actors, Malware families, Campaigns, TTPs, Tags, Products, Collection Logs, Alert Logs, Flashcards, Quiz Results</li></ul><p>This relational structure enables deep correlation: which threat actor uses which malware, which malware exploits which CVE, which CVE affects which product, which article mentions which IOC. SQLite with WAL mode handles concurrent reads from the API and dashboard while the collector writes.</p><h3>Correlation Engine</h3><p>The analyzer module connects the dots:</p><ul><li><strong>Entity graph</strong> — Builds a relationship graph between actors, malware, campaigns, IOCs, and CVEs. Visualized as an interactive network in the dashboard.</li><li><strong>Trend detection</strong> — Identifies patterns: rising threat actors, most-exploited CVEs, sector-specific targeting.</li><li><strong>MITRE ATT&CK heatmap</strong> — A tactic × technique matrix colored by frequency, showing which attack techniques are trending in collected intelligence.</li><li><strong>Threat scoring</strong> — Computes a global threat score based on monitored technologies and sectors, weighted by severity and exploit availability.</li><li><strong>STIX 2.1 export</strong> — Converts the internal knowledge base into the standard CTI sharing format.</li></ul><h3>API (FastAPI)</h3><p>A full REST API with <strong>20+ endpoints</strong> documented via Swagger UI:</p><ul><li>CRUD for articles, CVEs, IOCs, threat actors</li><li>Advanced filtering (severity, date range, source, category)</li><li>Analysis endpoints: timeline, trends, entity graph, MITRE heatmap</li><li>Export: STIX 2.1, CSV, JSON, TXT</li><li>Operations: trigger collection, trigger processing, flashcard retrieval</li></ul><p>Built with FastAPI + Uvicorn, with Pydantic models for request/response validation. CORS enabled for local development.</p><h3>Dashboard (Streamlit + Plotly)</h3><p>The dashboard provides <strong>10 interactive views</strong>:</p><ol><li><strong>Overview</strong> — KPIs, global threat score gauge, critical articles</li><li><strong>Articles</strong> — Search, filter, read, favorite, with LLM-generated summaries</li><li><strong>Vulnerabilities</strong> — CVE listing with CVSS scores, EPSS probabilities, exploit availability flags</li><li><strong>IOCs</strong> — Search by type and value, with source context</li><li><strong>Threat Actors</strong> — Detailed profiles: aliases, origin, target sectors, linked TTPs</li><li><strong>Trends</strong> — Bar charts of most active actors, most seen malware, category distribution</li><li><strong>MITRE ATT&CK</strong> — Interactive heatmap with Plotly, filterable by time period</li><li><strong>Graph</strong> — Entity relationship network visualization</li><li><strong>Learning</strong> — LLM-generated flashcards with adaptive quiz mode</li><li><strong>Operations</strong> — Source management, manual collection triggers, exports, maintenance</li></ol><h2>3 — The Alerting System</h2><p>CTI Sentinel supports <strong>5 notification channels</strong>:</p><ul><li><strong>Desktop notifications</strong> — Native Linux/macOS/Windows alerts</li><li><strong>Discord</strong> — Webhook with rich embeds (severity color-coded)</li><li><strong>Telegram</strong> — Bot API integration</li><li><strong>Slack</strong> — Webhook with formatted messages</li><li><strong>Email</strong> — SMTP with HTML templates</li></ul><p>Alert rules are configurable: severity threshold, cooldown period, per-channel filtering. A daily digest summarizes the most important findings.</p><h2>4 — The Scheduler</h2><p>APScheduler manages automated operations at multiple frequencies:</p><ul><li><strong>Every 30 minutes</strong> — RSS feed collection</li><li><strong>Every 2 hours</strong> — API source collection (NVD, OTX, abuse.ch)</li><li><strong>Every 6 hours</strong> — MITRE ATT&CK sync</li><li><strong>Daily</strong> — Database backup, cache cleanup, enrichment passes, digest report</li></ul><p>The scheduler runs as a daemon process — start it and forget it. It handles retries, error recovery, and logging automatically.</p><h2>5 — Docker Deployment</h2><p>The entire stack is containerized:</p><ul><li><strong>Ollama</strong> — LLM service (port 11434), with optional GPU passthrough</li><li><strong>API</strong> — FastAPI (port 8000)</li><li><strong>Dashboard</strong> — Streamlit (port 8501)</li><li><strong>Scheduler</strong> — Background daemon</li></ul><p>One <code>docker-compose up -d</code> and you're running. For CPU-only setups, just comment out the GPU resource block.</p><h2>6 — Tech Stack</h2><table><tr><th>Component</th><th>Technology</th></tr><tr><td>Language</td><td>Python 3.10+</td></tr><tr><td>Database</td><td>SQLAlchemy + SQLite (WAL) / PostgreSQL</td></tr><tr><td>API</td><td>FastAPI + Uvicorn</td></tr><tr><td>Dashboard</td><td>Streamlit + Plotly</td></tr><tr><td>LLM</td><td>Ollama (Mistral 7B / Llama3 8B)</td></tr><tr><td>Scheduler</td><td>APScheduler</td></tr><tr><td>HTTP</td><td>aiohttp (async)</td></tr><tr><td>RSS</td><td>feedparser</td></tr><tr><td>Containers</td><td>Docker + Docker Compose</td></tr></table><h2>7 — What I Learned</h2><p>Building CTI Sentinel taught me more about threat intelligence than any course or certification prep:</p><ul><li><strong>Data modeling matters</strong> — The 14-model schema with M2M relationships was the hardest part. Getting entity relationships right determines whether your correlation engine produces useful output or noise.</li><li><strong>LLM prompts are code</strong> — The CTI-specific prompts went through dozens of iterations. Severity scoring, IOC extraction, TTP mapping — each requires precise instructions to avoid hallucination and maintain consistency.</li><li><strong>Collection is messy</strong> — RSS feeds break, APIs rate-limit you, data formats change, duplicates pile up. The collector base class with caching and deduplication was essential.</li><li><strong>Correlation is where the value is</strong> — Individual articles, CVEs, and IOCs are just data points. The graph connecting them is intelligence. Building the correlation engine changed how I think about threats.</li><li><strong>Local LLMs are viable</strong> — Mistral 7B on a decent GPU processes articles in seconds. No API costs, no data leakage, no vendor dependency. The quality is more than sufficient for structured extraction tasks.</li></ul><h2>The Bottom Line</h2><p>CTI Sentinel isn't a production SOC tool. It's a <strong>learning platform</strong> — a way to understand how threat intelligence actually works by building every component yourself. From RSS parsing to STIX export, from IOC regex to MITRE heatmaps, from LLM prompts to entity graphs.</p><p>If you're studying CTI, preparing for a SOC/CERT role, or just want to understand what happens inside commercial platforms like MISP, OpenCTI, or ThreatConnect — building something like this is the fastest way to get there.</p><p>The project is open-source: <a href='https://github.com/Roockbye/CTI_tools' target='_blank' rel='noopener'>github.com/Roockbye/CTI_tools</a></p>",
    "date": "2026-02-16T12:00:00Z",
    "tags": ["CTI", "threat-intelligence", "OSINT", "MITRE", "LLM", "Ollama", "FastAPI", "Python", "open-source"]
  },
  {
    "id": "dolphinattack",
    "title": "DolphinAttack: Ultrasonic Injection on Voice Assistants",
    "category": "research",
    "summary": "How inaudible ultrasonic commands exploit MEMS microphone non-linearities to silently control Siri, Alexa, Google Assistant, and any device with a microphone — no interaction required, no sound heard.",
    "content": "<h2>DolphinAttack: Ultrasonic Injection on Voice Assistants</h2><p>This attack doesn't target a network protocol, an encryption scheme, a server, or an API. It targets <strong>your voice</strong> — or more precisely, the <strong>voice processing pipeline</strong> inside modern assistants like Siri, Alexa, Google Assistant, and Cortana, as well as the MEMS microphones found in virtually every smartphone.</p><p>The principle is as simple as it is disturbing: <strong>make a voice assistant hear a perfectly clear vocal command at a frequency that humans cannot perceive</strong>.</p><h2>1 — How a Voice Assistant Hears You</h2><p>A modern voice assistant processes sound through four successive layers:</p><h3>The MEMS Microphone</h3><p>Converts air vibrations into an electrical signal. Critically, it is sensitive to <strong>frequencies above 20 kHz</strong> — even though it's not designed to process them.</p><h3>The Analog Front-End</h3><p>Handles amplification, filtering, and analog-to-digital conversion. At this stage: no security, no contextual filtering, no ML model. Everything that enters is treated as trustworthy.</p><h3>The Demodulation / Reconstruction Module</h3><p>A modulated ultrasonic signal can be \"folded\" back into the audible band through <strong>intermodulation</strong>. In other words: <em>the hardware creates an audible voice that no one ever spoke</em>.</p><h3>The Speech Recognition Engine</h3><p>Receives a perfectly legible voice command: \"Open the door\", \"Call Mom\", \"Send money\", \"Visit malicious-website.com\". At no point does the system detect that the signal is <strong>non-human</strong>.</p><h2>2 — The Technical Principle: Ultrasonic Modulation</h2><p>DolphinAttack exploits a simple physical reality: <strong>MEMS microphones are not deaf to ultrasound</strong>. They're not supposed to hear them, but the design of their membrane and circuitry means they do anyway.</p><p>The attack flow:</p><ol><li>Take a human voice command (e.g., \"Hey Siri, open the front door\")</li><li>Convert it to a digital signal</li><li><strong>Amplitude-modulate (AM)</strong> it onto an ultrasonic carrier, typically 25–30 kHz — completely inaudible to humans</li><li>Broadcast via an ultrasonic transducer</li></ol><p>The MEMS microphone receives the ultrasonic wave, and the analog front-end produces a <strong>spectral folding effect</strong>: the voice command re-emerges in the audible band, but <strong>only for the machine</strong>.</p><p>The result: the assistant receives a perfectly clear command that no human in the room ever heard.</p><h2>3 — Real-World Attack Conditions</h2><p>Contrary to what you might expect, DolphinAttack doesn't require expensive equipment, close physical proximity, or laboratory conditions.</p><h3>Typical Hardware</h3><ul><li>An ultrasonic transducer ($10–40)</li><li>A small Class D amplifier</li><li>A portable power source</li><li>A Raspberry Pi, ESP32, rooted smartphone, or laptop</li></ul><h3>Effective Range</h3><ul><li>1–3 meters for stable command injection</li><li>Up to 5 meters with a directional transducer</li></ul><h3>Vulnerable Devices</h3><ul><li>iPhone (Siri)</li><li>Android (Google Assistant)</li><li>Amazon Echo (Alexa)</li><li>Microsoft Cortana</li><li>Connected cars with voice commands</li><li>Smart locks</li><li>Home automation devices</li><li>ISP set-top boxes</li><li>Enterprise voice assistants</li></ul><p>None of them properly filter ultrasonic signals.</p><h2>4 — Practical Attack Scenarios</h2><h3>Smart Home / Physical Access</h3><p>\"Hey Siri, open the front door.\" — \"Alexa, unlock the door.\"</p><h3>Phone Hijacking</h3><p>\"Call 555-0123.\" — \"Send an SMS to…\" — \"Open Safari and go to malware-site.com.\"</p><h3>Banking Fraud (via voice navigation)</h3><p>\"Open bank app.\" — \"Transfer $200 to X.\"</p><h3>Smartphone Phishing</h3><p>\"Open Chrome to phishing.com/login.\" — \"Turn off Wi-Fi.\"</p><h3>Silent Enterprise Attacks</h3><p>\"OK Google, turn on Bluetooth.\" — \"Pair with malicious device.\" — \"Download file from attacker server.\"</p><h3>Vehicle Attacks</h3><p>\"Call emergency services.\" — \"Navigate to X.\"</p><h3>Dormant Malware Activation</h3><p>\"Hey Siri, enable VoiceOver.\" (bypasses touch interface) — \"Open URL X.\" (malware dropper)</p><p>All of these commands can be triggered <strong>in the middle of a room, in complete silence</strong>.</p><h2>5 — Why It Works: Three Structural Flaws</h2><h3>1. MEMS Microphones Hear Ultrasound</h3><p>They lack a strict hardware filter to block frequencies above 20 kHz.</p><h3>2. Analog Front-Ends Generate Intermodulation</h3><p>They transform an AM ultrasonic signal into an audible one — an unintended demodulation.</p><h3>3. ASR Engines Don't Verify Origin</h3><p>Automatic Speech Recognition systems don't detect the source of the sound, don't validate whether it's human, and only check its <strong>linguistic structure</strong>. The entire pipeline treats the signal as normal.</p><h2>6 — Why It's Undetectable</h2><p>The attack is virtually invisible:</p><ul><li>No system alerts</li><li>No application detects the intrusion</li><li>No antivirus can catch it</li><li>The microphone produces a perfectly valid signal</li><li>No abnormal amplitude in the audible spectrum</li><li>No logical signature</li><li>No physical interaction required — no touch, no unlock</li></ul><p>The user hears nothing. The assistant obeys perfectly.</p><h2>7 — Attack Variants</h2><h3>SurfingAttack (Ultrasound via Solid Surfaces)</h3><p>Commands travel through vibrations in tables, metal, walls, and glass. No line of sight needed.</p><h3>NOUIN (Non-linear Ultrasound Injection)</h3><p>Exploits deeper microphone non-linearities for increased range.</p><h3>ARSonic Attack</h3><p>Uses directional ultrasound for long-range injection.</p><h3>Inaudible Backdoor via Speaker Ultrasound</h3><p>A YouTube video can contain an inaudible signal that triggers a hidden voice command. You watch a video, and your assistant makes a call without you knowing.</p><h2>8 — Mitigations (and Why They're Limited)</h2><p><strong>This bug cannot be fixed in software.</strong> It's a <strong>hardware problem</strong> rooted in microphone design.</p><h3>Hardware Low-Pass Filter (&gt;20 kHz)</h3><p>Low adoption — adds manufacturing cost.</p><h3>ML-Based Ultrasound Detection Models</h3><p>Expensive, increases latency, rarely deployed at scale.</p><h3>Context Verification</h3><p>E.g., \"Assistant unavailable when screen is off.\" But easily bypassed (SurfingAttack, secondary activations).</p><h3>Custom Wake Phrase</h3><p>Doesn't protect against silent commands <em>after</em> activation.</p><h3>Biometric Voice Recognition</h3><p>Still immature. And vulnerable to modified replays.</p><p>In summary: <strong>the attack targets a fundamental weakness in modern audio hardware</strong>.</p><h2>The Bottom Line</h2><p>DolphinAttack doesn't break any key, doesn't hack any protocol, doesn't bypass any permission. It simply uses what the microphone hears, what the front-end transforms, and what the ASR interprets.</p><p>The voice assistant isn't being tricked — it hears exactly what it's supposed to hear. And if your security relies on the assumption that <em>you</em> can't hear the command… then someone else can speak it for you.</p>",
    "date": "2025-04-10T09:00:00Z",
    "tags": ["ultrasound", "voice-assistant", "MEMS", "DolphinAttack", "hardware", "IoT", "physical-security"]
  },
  {
    "id": "cloud-control-plane-ghost",
    "title": "The Cloud Control-Plane Ghost: Exploiting Meta-IAM Temporal Inconsistencies",
    "category": "research",
    "summary": "A deep dive into how race conditions in cloud control-plane IAM propagation can produce 'ghost tokens' — cryptographically valid credentials that belong to no one, yet carry cross-tenant privileges invisible to any audit log.",
    "content": "<h2>The Cloud Control-Plane Ghost</h2><p>This attack doesn't target a server, an endpoint, a bucket, a secret, or a VM. It targets <strong>the space between all of them</strong> — the <strong>meta-IAM layer</strong>, the identity fabric that cloud customers never see. This is the logical overlay of the control-plane: the administrative brain of the cloud that ultimately decides who is allowed to do what.</p><p>This layer orchestrates our identities, roles, tokens, and ACLs, but it lives <strong>above our tenant boundary</strong> — outside our perimeter of control. It's where cloud providers run their token-signing engines, IAM replication motors, policy resolvers, consistency oracles, and multi-region caches that determine whether a permission is \"effective\" or still \"pending\".</p><p>Think of it as the cloud's kernel. And this attack forces that kernel to produce an <strong>impossible artifact</strong>.</p><h2>1 — The Hidden Architecture of the Control-Plane</h2><p>Above every public API (<code>ListObjects</code>, <code>GetObject</code>, <code>AssumeRole</code>, <code>Decrypt</code>, etc.) lives a <strong>meta-API</strong> that customers can never call directly. It's reserved for the control-plane and handles:</p><ul><li>Propagating role updates across regions</li><li>Maintaining weak ACID consistency of the IAM model (best-effort, not instantaneous)</li><li>Replicating policies between regions</li><li>Recomputing authorization trees</li><li>Resolving complex conditions (<code>ArnEquals</code>, <code>IpNotEquals</code>, etc.)</li></ul><p>This meta-API relies on:</p><ul><li>A <strong>Replicated State Machine (RSM)</strong> — a distributed system ensuring all nodes apply changes in the same order</li><li><strong>Paxos/Raft-like consensus journals</strong> for multi-region synchronization</li><li><strong>Heavily regionalized caches</strong></li><li><strong>Persisted session contexts</strong></li><li><strong>Asynchronous delta-resolvers</strong> that merge partial updates without blocking the system</li></ul><p>The critical detail: <strong>IAM modifications are not instantaneous</strong>. They pass through an intermediate stage called the <strong>\"authorization intent state\"</strong> — where the cloud considers the role as applied, but the update hasn't yet propagated to all internal layers. This window, lasting milliseconds to seconds, is precisely where the attack is born.</p><h2>2 — The Vulnerability: Temporal Inconsistency in State Propagation</h2><p>This isn't a CVE. It's an <strong>architectural consequence</strong> — a race condition between three events:</p><ol><li>The moment a role is updated</li><li>The moment a token is minted (created and cryptographically signed)</li><li>The moment the final ACLs are resolved</li></ol><p>Here's the exact sequence:</p><ol><li>The attacker requests a <strong>scoped token</strong> via a legitimate API (e.g., a token limited to a specific bucket).</li><li>The token is created and signed, but <strong>not yet validated</strong> on the authorization side.</li><li>At that exact moment, an admin IAM role from <strong>another tenant</strong> (in the same region) is modified — typically adding a KMS or storage permission.</li><li>The propagation engine merges both events into the same commit window.</li><li>The resolver mistakenly associates the pending token with the role that was just modified.</li><li>The limited token becomes a <strong>cross-tenant token with elevated privileges</strong>.</li></ol><p>This is an <strong>interleaving bug</strong>: two asynchronous events intercalated in the wrong order inside the cloud provider's internal scheduler.</p><p>The cloud emits a token that has no identity, no tenant, but possesses an incoherent set of permissions. This is what we call a <strong>ghost token</strong>.</p><h2>3 — Properties of the Ghost Token</h2><p>The ghost token has unique characteristics:</p><ul><li><strong>Valid issuer</strong> — signed by the provider's infrastructure</li><li><strong>Valid signature</strong> — produced by the internal HSM (Hardware Security Module)</li><li><strong>Empty subject</strong> — no identity attached</li><li><strong>Phantom tenantId</strong> — pointing to a non-existent zone</li><li><strong>Incoherent scope</strong> — permissions that don't match any existing policy</li><li><strong>Unknown session context</strong></li><li><strong>IAM claims</strong> that correspond to no real policy</li></ul><p>Internally, it's classified as an <strong>orphaned IAM context</strong>. For public APIs: it's perfectly valid. For tenants: it's invisible — nothing links it to them. For the control-plane: it's a glitch, but a \"logically valid\" one.</p><h2>4 — What You Can Do With a Ghost Token</h2><p>The ghost token grants operations that depend not on <em>your</em> permissions, but on <strong>the provider's internal permissions</strong>:</p><h3>Cross-Tenant Object Listing</h3><p>Browse buckets belonging to other tenants.</p><h3>Cross-Tenant Object Retrieval</h3><p>Download production objects from other customers' storage.</p><h3>Internal KMS Key Export</h3><p>Extract master keys from another tenant via meta-APIs invisible to the public.</p><h3>Snapshot Access</h3><p>Read disk volumes from other accounts via <code>ListSnapshots</code> / <code>ReadSnapshot</code>.</p><h3>IAM Topology Enumeration</h3><p>Access other customers' IAM topology — real names, roles, policies, groups, MFA flags, and valid API keys — through <code>DescribeUsers</code> / <code>DescribePolicies</code>. Impossible via public API, but possible when the resolver binds the ghost token to the wrong IAM node.</p><h3>Internal Keystore Access</h3><p>Retrieve internal keys, intermediate certificates, and platform-generated secrets. Many providers use shared keystores isolated by logical namespaces — the ghost token breaks that namespace boundary.</p><h2>5 — Why It's Invisible to the Tenant</h2><p>This is the most unsettling part: the ghost token <strong>generates zero logs in the tenant's audit trail</strong>.</p><ul><li>The token isn't mapped to your identity store — your user directory never sees it, so nothing is recorded.</li><li>The control-plane treats these calls as \"internal\" — like the cloud performing its own maintenance checks, not client actions.</li><li>Exported buckets/snapshots appear as system operations classified as \"internal maintenance\".</li><li>KMS accesses fall under \"meta-calls\" — internal operations for coherence and key verification that never appear in customer logs.</li><li>The provider simply doesn't surface these logs in customer-visible journals.</li></ul><p>So if someone reads your buckets, exports your snapshots, enumerates your policies, and steals your KMS keys — <strong>your logs show nothing</strong>.</p><p>The only visible sign is a subtle statistical drift in metrics: more downloads than authentication events, more API calls than identity mappings.</p><h2>6 — Detection Through Side Effects</h2><p>You can't detect the ghost token itself. You detect <strong>what it causes</strong>:</p><h3>API Calls Without Correlated Identity</h3><p>A successful <code>GET Object</code> with no corresponding authentication log entry. Every cloud action should have an identity — here, there's none.</p><h3>Negative Delta Between Access Logs and API Logs</h3><p>42 downloads but only 41 auth events. An accounting gap that's impossible under normal usage.</p><h3>Cross-Region Access on Non-Replicated Buckets</h3><p>A region-local bucket receiving access from another region — highly suspicious.</p><h3>Access to Dormant Snapshots</h3><p>Automated systems almost never read old, idle disk snapshots. Someone accessing them is a red flag.</p><h3>Access Without Internal Referrer</h3><p>CI/CD pipelines have recognizable access patterns. Ghost token calls have none.</p><h3>KMS Access Without Cryptographic Operation</h3><p>A key export with no preceding encrypt/decrypt operation never happens in normal usage.</p><h2>7 — Mitigations</h2><p><strong>You cannot prevent this attack.</strong> It doesn't target you — it targets the cloud's internal infrastructure, where you have zero control. You can only limit the impact by creating an <strong>independent log reality</strong> the provider can't manipulate or mask.</p><h3>Impose an External Source of Truth</h3><p>Export logs to an external SIEM (outside the cloud), a WORM vault (write-once-read-many), or an independently encrypted log pipeline.</p><h3>Audit for Impossible Access Patterns</h3><p>Set up detection rules for logical impossibilities: <code>GetObject</code> without <code>AuthEvent</code>, snapshot exports with audit gaps, KMS access with no associated identity.</p><h3>Differential Analysis</h3><p>Cross-compare provider logs, internal application logs, network logs, and storage metrics. A ghost token always creates a discrepancy between these layers.</p><h3>Alert on Unmapped Access</h3><p>Some providers expose an often poorly-documented internal metric — <code>UnattributedAccess</code> or <code>UnlinkedContextEvents</code>. In plain terms: \"something accessed something, but we don't know who.\"</p><h2>The Bottom Line</h2><p>We assume that every action in our cloud environment originates from an identity we own. The ghost token proves this assumption wrong.</p><p>The cloud can generate identities <strong>that belong to no one</strong>, and those identities can have <strong>more privileges than we do</strong>. At that point, our firewalls, ACLs, and IAM policies aren't guardrails anymore — they're decorations applied <strong>after</strong> the cloud's real internal decision. And here, <strong>that internal decision lied</strong>.</p>",
    "date": "2025-09-22T10:30:00Z",
    "tags": ["cloud", "IAM", "control-plane", "ghost-token", "race-condition", "cross-tenant", "security-architecture"]
  },
  {
    "id": "wifi-beacon-timeshift",
    "title": "The Wi-Fi Beacon Time-Shift Trick: Temporal Compromise of 802.11 Roaming",
    "category": "research",
    "summary": "How a simple timestamp manipulation in 802.11 beacon frames can silently force clients to roam onto an attacker-controlled access point — no deauthentication, no brute-force, no visible attack.",
    "content": "<h2>The Wi-Fi Beacon Time-Shift Trick</h2><p>This attack targets something most people never think about: <strong>the way Wi-Fi access points use an internal timestamp to prove they're the most synchronized node on the network</strong>. By manipulating a single field in an 802.11 beacon frame, an attacker can force a client to silently leave a legitimate AP and connect to a rogue one — without deauthentication, without brute-force, and without any visibly malicious packet.</p><h2>1 — How 802.11 Roaming Actually Works</h2><p>In a Wi-Fi network, access points constantly broadcast small management frames called <strong>beacons</strong> — roughly <strong>10 times per second</strong> (every 100 ms). These beacons announce the AP's presence and carry essential metadata:</p><ul><li>SSID (network name)</li><li>BSSID (AP hardware address)</li><li>Channel</li><li>Capabilities</li><li><strong>TSF — Timing Synchronization Function</strong></li></ul><p>Beacons are sent <strong>in the clear</strong>, are <strong>unsigned</strong>, <strong>unauthenticated</strong>, and treated as purely informational.</p><h3>The TSF Timestamp</h3><p>Every beacon contains a 64-bit counter called the <strong>TSF (Timing Synchronization Function)</strong>. It increments at 1 MHz and represents the AP's internal clock — not real-world time, just a monotonically increasing metronome.</p><p>Why does it matter? Because the TSF is used to <strong>keep devices synchronized</strong>. The higher the timestamp, the more the AP is considered:</p><ul><li>Stable</li><li>Well-synchronized</li><li>A strong candidate for connection</li></ul><p>In many firmware implementations, the TSF influences:</p><ul><li>AP selection during roaming</li><li>Opportunistic roaming decisions</li><li>PMK cache management</li><li>Handoff triggering</li></ul><p><strong>And the TSF is neither signed nor verified. It's just a number.</strong></p><h2>2 — The Vulnerability: The Time-Shift Trick</h2><p>The attack exploits a subtle but real behavior in certain 802.11 roaming implementations: <strong>they treat a higher TSF value as evidence of a \"better\" access point</strong>. This is a side-effect of a design that's over 20 years old.</p><p>Here's the attack sequence:</p><ol><li>The attacker creates a rogue AP with the <strong>same SSID</strong> as the legitimate network (no need to spoof the BSSID).</li><li>They passively listen to legitimate beacons and replicate everything: channel, capabilities, Information Elements, rates, QoS, DTIM period, beacon interval.</li><li>They modify <strong>only the TSF timestamp</strong> — shifting it slightly ahead (a few milliseconds to a few seconds).</li><li>They broadcast these forged beacons at a slightly faster interval.</li><li>The client receives both sets of beacons. From its perspective, the attacker's AP appears \"fresher\", \"better synchronized\", and therefore <strong>preferable</strong>.</li><li>Certain implementations <strong>automatically roam</strong> to the rogue AP — without any user interaction.</li><li>Once connected to the rogue AP, the attacker achieves full man-in-the-middle position.</li></ol><p>All of this happens <strong>without deauthentication frames, without active attacks</strong> — nothing that resembles a traditional Wi-Fi exploit.</p><h2>3 — What an Attacker Can Do</h2><p>Once the client connects to the rogue AP, the possibilities are significant:</p><h3>Full MITM (even under WPA2/WPA3)</h3><p>The 4-way handshake runs through the attacker's AP, giving them a privileged position in the connection.</p><h3>Encryption Downgrade</h3><p>Some clients still accept WPA2 when WPA3 fails — especially in transition mode. The rogue AP can exploit this fallback behavior.</p><h3>Handshake Capture</h3><p>The attacker captures the WPA handshake for offline brute-force or PMK derivation.</p><h3>Traffic Injection</h3><p>DNS manipulation, HTTP redirects, proxy injection — the classic MITM toolkit becomes available.</p><h3>Enterprise Attack Surface</h3><ul><li>Session token theft</li><li>OIDC interception</li><li>Kerberos relay over Wi-Fi</li><li>Data exfiltration</li><li>Internal traffic analysis</li></ul><h3>No Visible Deauthentication</h3><p>The roaming looks completely natural — indistinguishable from a legitimate handoff.</p><h2>4 — Why It's Nearly Undetectable</h2><p>This is what makes the attack particularly dangerous: <strong>it uses no malicious packets</strong>.</p><p>It triggers:</p><ul><li>No deauthentication alerts</li><li>No BSSID spoofing alerts</li><li>No ARP spoofing alerts</li><li>No WPA/WPS attack signatures</li><li>No brute-force detection</li></ul><p>The attack uses only <strong>beacon frames — management frames that are normally unsecured by design</strong>. The client's roaming behavior looks like a natural handoff driven by a \"more reliable\" TSF value.</p><p>No wireless IDS detects this by default.</p><h2>5 — Detection Through Side Effects</h2><p>You can't detect the forged beacon directly. But you <strong>can</strong> detect what it causes:</p><h3>TSF Drift</h3><p>An abnormal gap between the AP's expected timestamp and the one perceived by the client.</p><h3>Roaming Without RSSI Change</h3><p>The client switches APs but the signal strength hasn't actually changed — suspicious.</p><h3>Out-of-Sequence PMK Derivation</h3><p>The client initiates a PMK exchange that the legitimate AP never requested.</p><h3>Unknown but \"Perfectly Synced\" BSSID</h3><p>A new AP appears with a suspiciously clean TSF — never seen before but behaving as if it's been running for hours.</p><h3>Abnormal Beacon Rate</h3><p>Beacons arriving more frequently than the legitimate AP (e.g., 80 ms instead of 100 ms).</p><h3>DHCP/DNS Anomalies Post-Roaming</h3><p>A classic indicator of MITM — new DHCP lease or DNS resolution changes right after a roaming event.</p><h2>6 — Mitigations</h2><ul><li><strong>WPA3 with Protected Management Frames (PMF)</strong> — Beacons remain unprotected, but reassociation frames are secured.</li><li><strong>BSSID whitelisting</strong> — Force clients to only connect to known BSSIDs, not just matching SSIDs.</li><li><strong>Reduce opportunistic roaming aggressiveness</strong> — Some clients roam too eagerly; tuning thresholds helps.</li><li><strong>TSF anomaly detection</strong> — Already present in some Cisco/Aruba firmware, flags abnormally high TSF values.</li><li><strong>Wireless IDS with TSF drift monitoring</strong> — Rare but available in enterprise-grade hardware.</li><li><strong>Fixed beacon interval enforcement</strong> — Prevents attackers from gaining an advantage through faster beacon rates.</li></ul><h2>The Bottom Line</h2><p>Wi-Fi security is built on cryptography — but <strong>the choice of which AP to connect to relies on a simple, unsigned clock counter</strong>. As long as that counter isn't cryptographically protected, an attacker can become the most \"synchronized\" AP on the network and silently take control.</p><p>The rogue AP doesn't lie. It just says: <strong>\"Check the time — I'm ahead.\"</strong></p><p>Hardware cost: under $20. An ESP32, a monitor-mode chipset, and a few lines of Scapy.</p>",
    "date": "2025-06-15T14:00:00Z",
    "tags": ["wifi", "802.11", "roaming", "beacon", "MITM", "TSF", "wireless-security"]
  }
]
